### Описание соревнования  
В соревновании **Predicting User Churn** требуется построить модель, прогнозирующую отток пользователей (churn) на основе исторических данных. Задача относится к классу бинарной классификации: для каждого пользователя нужно предсказать вероятность того, что он покинет сервис в заданный период.

**Цель**: максимизировать метрику оценки, предоставив точные вероятности оттока.

### Данные
#### Тренировочный набор (train.csv):

- Целевая переменная: churn (1 = ушёл, 0 = остался).


- Примеры признаков:

    - Демография (возраст, регион, пол).

    - Поведенческие метрики (частота входов, время сессии, покупки).

    - Технические параметры (устройство, ОС, канал привлечения).

#### Тестовый набор (test.csv):

- Те же признаки, что в тренировочном, но без столбца churn.

- Требуется предсказать churn для каждой строки.

#### Файл submissions (sample_submission.csv):

- Шаблон для отправки: столбцы user_id и churn_probability.

### Метрика оценки
**Основная метрика**: recall.

- Важно максимально выявлять пользователей, склонных к оттоку.

- Пропуск «рискованных» клиентов (ложноотрицательные ошибки, FN) критичен для бизнеса.

- Допустимы ложноположительные срабатывания (FP), если это помогает поймать больше реальных случаев оттока.

**Другие метрики оценки**: AUC-ROC и Precision


### Что было реализованно?

#### 1. Анализ данных

- Обработал пропуски, типы данных, выбросы, дублирующиеся строки.

- Визуализировал ключевые признаки.

- Проанализировал распределение целевой переменной **churn**, и баланс классов.  
    - Есть небольшой дисбаланс классов, но достаточный, чтобы модель могла различить эту разницу и обучиться.

- Проанализировал важность признаков через **permutation importance** на основе RandomForestClassifier. Построил диаграмму важности признаков. 

#### 2. Предобработка
- Заменил значения "No internet service" в HasDeviceProtection на "No"

- Закодировал категориальные переменные **One‑Hot**.

- Масштабировал числовые признаки **StandardScaler** для линейных моделей.

#### 3. Валидация

- Разделил тренировочные данные на train/validation (стратифицированно по "ClientPeriod").

#### 4. Базовая модель

- В качестве базовой модели использовал **Logistic Regression**.  

Настраивал гиперпараметры для линейных моделей через GridSearchCV  

#### 5. Эксперемент

Провел эксперемнт исключив следующее утверждение:
    
        Дисбалас классов может повлиять на конечный результат.

Использовал **UnderSampling** и **OverSampling** признаков, а так же их комбинацию.

**Вывод**: результат не дал прироста качества модели.

#### 6. Моделирование

- Использовал следующие модели: KNeighborsClassifier, Random Forest, CatBoost, StackingClassifier[logreg, RandomForest, KNN, CatBoost].

- Постоил матрицу ошибок "Confusion Matrix", которая наглядно показывает, как модель классификации справляется с предсказаниями и какие именно ошибки она допускает.

- Настраивал гиперпараметры для деревьев через Optuna и сохранял результаты подбора.

#### 7. Финальная модель

Наилучший результат показала модель StackingClassifier.  

Обуил модель и сохранил веса в "./model"

#### 8. Предсказание

- Получил вероятности оттока на тестовом наборе.


#### PS: Для управления зависимостями использовал **Poetry**.