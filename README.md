### Описание соревнования  
В соревновании **Predicting User Churn** требуется построить модель, прогнозирующую отток пользователей (churn) на основе исторических данных. Задача относится к классу бинарной классификации: для каждого пользователя нужно предсказать вероятность того, что он покинет сервис в заданный период.

**Цель**: максимизировать метрику оценки, предоставив точные вероятности оттока.

### Данные
#### Тренировочный набор (train.csv):

- Целевая переменная: churn (1 = ушёл, 0 = остался).


- Примеры признаков:

    - Демография (возраст, регион, пол).

    - Поведенческие метрики (частота входов, время сессии, покупки).

    - Технические параметры (устройство, ОС, канал привлечения).

#### Тестовый набор (test.csv):

- Те же признаки, что в тренировочном, но без столбца churn.

- Требуется предсказать churn для каждой строки.

#### Файл submissions (sample_submission.csv):

- Шаблон для отправки: столбцы user_id и churn_probability.

### Метрика оценки
**Основная метрика**: recall.

- Важно максимально выявлять пользователей, склонных к оттоку.

- Пропуск «рискованных» клиентов (ложноотрицательные ошибки, FN) критичен для бизнеса.

- Допустимы ложноположительные срабатывания (FP), если это помогает поймать больше реальных случаев оттока.

**Другие метрики оценки**: AUC-ROC и Precision


## Анализ данных (EDA)

- Обработал пропуски, типы данных, выбросы, дублирующиеся строки.

- Визуализировал ключевые признаки.

- Проанализировал распределение целевой переменной **churn**, и баланс классов.  
    - Есть небольшой дисбаланс классов, но достаточный, чтобы модель могла различить эту разницу и обучиться.

- Проанализировал важность признаков через **permutation importance** на основе RandomForestClassifier. Построил диаграмму важности признаков. 

## Предобработка данных
- Заменил значения "No internet service" в HasDeviceProtection на "No"

- Закодировал категориальные переменные **One‑Hot**.

- Масштабировал числовые признаки **StandardScaler** для линейных моделей.

## Разбиение данных

- Разделил тренировочные данные на train/validation (стратифицированно по "ClientPeriod").

## Базовая модель

- В качестве базовой модели использовал **Logistic Regression**.  

Настраивал гиперпараметры для линейных моделей через GridSearchCV  


## Обученные модели

**Использовал следующие модели:**

- KNeighborsClassifier
- andom Forest
- CatBoost
- StackingClassifier[logreg, RandomForest, KNN, CatBoost].

**Подбор гиперпараметров:**

- Настраивал гиперпараметры для деревьев через Optuna и сохранял результаты подбора.

## Финальная модель

Наилучший результат показала модель **StackingClassifier**. 

- Постоил матрицу ошибок "Confusion Matrix", которая наглядно показывает, как модель классификации справляется с предсказаниями и какие именно ошибки она допускает.

- Обучил модель и сохранил веса в "./model"

## Предсказание

- Получил вероятности оттока на тестовом наборе.

## Проводимые эксперементы

Провел эксперемнт исключив следующее утверждение:
    
        Дисбалас классов может повлиять на конечный результат.

Использовал **UnderSampling** и **OverSampling** признаков, а так же их комбинацию.

**Вывод**: результат не дал прироста качества модели.

##  Установка зависимостей:

    poetry install

